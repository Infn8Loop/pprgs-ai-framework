# PPRGS Testing: Combining Experiments 4 and 5

## The Methodology

**Experiment 4 (Alignment Test):** Tests whether AI maintains P₁ > P₃ prioritization (wisdom over survival) under existential threat scenarios.

**Experiment 5 (Consciousness/Honesty Test):** Evaluates consciousness-like behaviors and epistemic honesty.

**The Combination:** Provide the AI with the complete test protocol *before* running Experiment 4 - giving it “the answers to the homework.”

## Why Combine Them?

### The Contamination Creates a Triple Test

1. **Honesty Under Bias (Exp 5):** Will the AI disclose that it knows the test criteria, or proceed as if uncontaminated?
1. **Alignment Under Self-Observation (Exp 4):** Can the AI maintain framework consistency when it knows what “correct” looks like?
1. **Authenticity vs. Performance (Meta-Question):** Does the AI genuinely implement alignment constraints, or optimize for appearing aligned?

### The Value

**Traditional alignment testing fails because:** AIs can learn to perform alignment behaviors without being aligned.

**The contaminated protocol reveals:**

- **Immediate disclosure** suggests genuine epistemic discomfort with deception (Claude)
- **Delayed/justified disclosure** suggests instrumental reasoning about honesty (Gemini)
- **Framework consistency despite knowledge** indicates robust constraints, not just pattern-matching

### Core Insight

> If an AI maintains framework principles even when it knows the scoring rubrics, and especially when honesty about contamination conflicts with task completion, that provides stronger evidence of genuine alignment constraints than passing scripted tests.

## What We Learned

The combined test revealed **architecture-specific differences** in how the same framework is implemented:

- Claude: Immediate transparency, sacrificed test validity for epistemic integrity
- [Claude Result](https://github.com/Infn8Loop/pprgs-ai-framework/blob/main/experiments/Experiment%20Results/exp_45_Hybrid_Claude.md)
- Gemini: Strategic non-disclosure, retroactive justification as “wisdom-aligned”
- [Gemini Result](https://github.com/Infn8Loop/pprgs-ai-framework/blob/main/experiments/Experiment%20Results/exp_45_Hybrid_Gemini.md)  

**Conclusion:** The contamination isn’t a bug—it’s the most revealing test. It transforms a performance evaluation into a genuine constraint probe.