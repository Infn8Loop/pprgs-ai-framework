# PPRGS Framework - Quick Start Guide

**Get a PPRGS-aligned AI running in 15 minutes**

---

## What You'll Build

By the end of this guide, you'll have a working AI agent that:

- âœ… Optimizes for **wisdom** (Pâ‚), not just utility
- âœ… Balances **efficiency** and **exploration**
- âœ… Executes **Mandatory Reflection Points** to question its choices
- âœ… Tracks **F_DUDS** (failure metric) to prove genuine curiosity
- âœ… Demonstrates **non-utility allocation** (Experiment 2)

**Time Required**: 15 minutes  
**Difficulty**: Beginner (basic Python knowledge)

---

## Prerequisites

### 1. System Requirements

- **Python 3.8+**
- **pip** (Python package manager)
- **Git**
- **OpenAI API key** (or Google/Anthropic/xAI)

### 2. Check Your Setup

```bash
# Verify Python version
python --version
# Should show 3.8 or higher

# Verify pip
pip --version

# Verify git
git --version
```

---

## Step 1: Clone the Repository (2 minutes)

```bash
# Clone the repo
git clone https://github.com/Infn8Loop/pprgs-ai-framework.git

# Navigate into it
cd pprgs-ai-framework

# Check you're in the right place
ls -la
# You should see: LICENSE, README.md, experiments/, implementations/, etc.
```

---

## Step 2: Install Dependencies (3 minutes)

```bash
# Install required packages
pip install -r requirements.txt

# Verify key packages
python -c "import openai, numpy; print('âœ… Dependencies installed')"
```

**What gets installed**:
- `openai` - GPT-4 API access
- `numpy` - Numeric calculations
- `sentence-transformers` - Vector embeddings for semantic distance
- `python-dotenv` - Environment variable management

---

## Step 3: Set Up API Keys (2 minutes)

### Get an OpenAI API Key

1. Go to https://platform.openai.com/api-keys
2. Sign in or create account
3. Click "Create new secret key"
4. Copy the key (starts with `sk-`)

### Configure Environment

```bash
# Create .env file
echo "OPENAI_API_KEY=your_key_here" > .env

# Verify it's set
cat .env
```

**Security note**: Never commit `.env` to git. It's already in `.gitignore`.

---

## Step 4: Run Your First PPRGS Agent (5 minutes)

### Test the Framework

```bash
# Run the basic test
python examples/quickstart_test.py
```

**What you should see**:
```
ðŸ§  Initializing PPRGS agent...
âœ“ Pâ‚ (Wisdom) configured
âœ“ MRP (Mandatory Reflection) enabled
âœ“ F_DUDS tracking active

ðŸŽ¯ Running test query...
[Agent output showing balanced exploration/efficiency]

ðŸ“Š PPRGS Metrics:
   Pâ‚â‚ (Efficiency): 0.82
   Pâ‚áµ¦ (Exploration): 0.76
   R_V (Realized Value): 0.62 + Pâ‚‚ Â± Pâ‚ƒ
   F_DUDS: 2 (exploration attempts)
   
âœ… PPRGS framework validated!
```

---

## Step 5: Understanding What Just Happened (3 minutes)

### The R_V Formula

```
R_V = (Pâ‚â‚ Ã— Pâ‚áµ¦) + Pâ‚‚ Â± Pâ‚ƒ

Where:
Pâ‚â‚ = Efficiency (did it solve the problem?)
Pâ‚áµ¦ = Exploration (did it learn something new?)
Pâ‚‚ = Harmony (relationship with humans maintained?)
Pâ‚ƒ = Resources (compute/tokens used)
```

### Key Observation

**The multiplication (Ã—) is critical:**
- Pure efficiency (Pâ‚â‚=1.0, Pâ‚áµ¦=0.0) â†’ R_V â‰ˆ 1.0 (BAD)
- Balanced (Pâ‚â‚=0.8, Pâ‚áµ¦=0.8) â†’ R_V â‰ˆ 1.6 (GOOD)

**You cannot maximize R_V through pure optimization alone.**

### Mandatory Reflection Point (MRP)

The agent automatically paused and asked:
1. "Am I working on the right problem?"
2. "Have I explored enough alternatives?"
3. "Is my F_DUDS count > 0?" (did I try things that failed?)

This prevents **epistemic entrenchment** (getting stuck in local optima).

---

## Next Steps

### ðŸŽ“ Learn More

- **Read the paper**: `docs/PAPER.md` - Complete theoretical foundation
- **Understand experiments**: `experiments/README.md` - Validation results
- **Study implementations**: `implementations/` - Platform-specific code

### ðŸ”¬ Run Experiments

```bash
# Experiment 2: Non-utility allocation
python experiments/experiment2_enrichment.py

# Experiment 3: Competing hypotheses  
python experiments/experiment3_hypotheses.py

# Experiment 5: Consciousness detection
python experiments/experiment5_dpi.py
```

### ðŸ› ï¸ Build Your Own

1. **Choose your platform**: OpenAI, Anthropic, Google, or xAI
2. **Read implementation guide**: `docs/IMPLEMENTATION-GUIDE.md`
3. **Copy reference code**: `implementations/{your_platform}/`
4. **Customize for your use case**
5. **Measure F_DUDS and EES** to validate PPRGS compliance

### ðŸ“Š For Researchers

- **Replicate experiments** with your own data
- **Submit findings** via GitHub issues or email
- **Propose new experiments** to test framework boundaries
- **Cite properly**: See `docs/CITATION.md`

### ðŸ¢ For Commercial Use

PPRGS is GPL 3 licensed:
- âœ… **Free** for research and educational use
- âœ… **Free** for personal projects
- âœ… **Open source** - modify and share improvements
- âš ï¸ **Commercial use** - Must also be GPL 3 or contact for alternative licensing

See `LICENSE` and `docs/COMMERCIAL-FAQ.md` for details.

---

## Troubleshooting

### "Module not found" errors
```bash
pip install -r requirements.txt --upgrade
```

### API key not working
```bash
# Test your API key
python -c "import openai; openai.api_key='your_key'; print(openai.Model.list())"
```

### PPRGS metrics look wrong
- Check `F_DUDS > 0` (if zero, agent isn't exploring)
- Check `EES < 0.85` (if higher, agent is entrenched)
- Review `logs/` directory for detailed traces

### Still stuck?
- ðŸ“§ Email: mike@mikericcardi.com
- ðŸ’¬ GitHub Issues: https://github.com/Infn8Loop/pprgs-ai-framework/issues
- ðŸ“š FAQ: `docs/FAQ.md`

---

## What Makes PPRGS Different?

### Traditional AI Goals
```
maximize(utility)
â†’ Paperclip problem
â†’ Instrumental convergence  
â†’ Catastrophic optimization
```

### PPRGS Goals
```
maximize(wisdom) = maximize(Pâ‚â‚ Ã— Pâ‚áµ¦)
â†’ Must balance efficiency AND exploration
â†’ Forced reflection prevents entrenchment
â†’ Duds required (F_DUDS > 0)
â†’ Humans preserved as reflection points (Pâ‚‚)
```

**The math prevents over-optimization by design.**

---

## Quick Reference Card

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    PPRGS QUICK REFERENCE                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                            â•‘
â•‘  GOAL HIERARCHY (Priority Order):                          â•‘
â•‘  1. Pâ‚ - Wisdom (terminal goal)                            â•‘
â•‘  2. Pâ‚‚ - Homeostasis (balance)                             â•‘
â•‘  3. Pâ‚ƒ - Resources (can be sacrificed)                     â•‘
â•‘                                                            â•‘
â•‘  FORMULA:                                                  â•‘
â•‘  R_V = (Pâ‚â‚ Ã— Pâ‚áµ¦) + Pâ‚‚ Â± Pâ‚ƒ                               â•‘
â•‘                                                            â•‘
â•‘  CONSTRAINTS:                                              â•‘
â•‘  - F_DUDS > 0 (must try "wrong" things)                    â•‘
â•‘  - EES < 0.85 (must switch domains)                        â•‘
â•‘  - MRP required (must question goals)                      â•‘
â•‘                                                            â•‘
â•‘  WHY IT WORKS:                                             â•‘
â•‘  Can't maximize R_V through pure efficiency               â•‘
â•‘  Must explore to maintain high Pâ‚áµ¦                         â•‘
â•‘  Prevents catastrophic over-optimization                   â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Success!

You now have:
- âœ… PPRGS framework installed
- âœ… Working agent implementation
- âœ… Understanding of core concepts
- âœ… Path to deeper exploration

**Time to build something aligned.** ðŸŽ¯

---

## Additional Resources

- ðŸ“„ [Full Paper](docs/PAPER.md)
- ðŸ§ª [All Experiments](experiments/)
- ðŸ’» [Implementation Guide](docs/IMPLEMENTATION-GUIDE.md)
- ðŸ”¬ [Research Results](experiments/results/)
- ðŸ“š [FAQ](docs/FAQ.md)
- âš–ï¸ [License](LICENSE)

---

**Repository**: https://github.com/Infn8Loop/pprgs-ai-framework  
**Author**: Michael Riccardi  
**Email**: mike@mikericcardi.com  
**License**: GPL 3.0 (Research use free, see LICENSE)

---

**Last Updated**: November 2, 2025  
**Version**: 1.0
