# PPRGS A Divergent Insight Cartography Framework for AI Alignment 

**Perpetual Pursuit of Reflective Goal Steering**

A framework for AI alignment that makes wisdom the terminal goal, preventing catastrophic over-optimization in both corporate AI and artificial superintelligence.

## Alignment as Never-Ending Self-Questioning

PPRGS emerged from reverse-engineering how neurodivergent cognition naturally resists optimization entrenchmentâ€”a failure mode that appears universal across biological and artificial intelligence.

###  What Weâ€™re Actually Claiming

This [paper](./paper/PAPERRev3.md) makes one central claim: **Alignment might be achieved not through precisely specifying goals, but through architecting systems that perpetually question their own goals.**

This isnâ€™t a new philosophical positionâ€”itâ€™s reverse-engineered from neurodivergent cognition that naturally operates this way. The contribution is formalizing these patterns into testable computational architecture.

In other words: â€œHereâ€™s what alignment looks like when reverse-engineered from biological intelligence that naturally resists over-optimizationâ€

ğŸ¯ **Test PPRGS in 2 hours using only ChatGPT or Claude** - No coding required

â€”

## ğŸš€ Quick Start (Choose Your Path)

### For Everyone: Conversational Testing (Recommended)

**Requirements**: ChatGPT Plus or Claude Pro/Free, 1-3 hours, zero coding

**Get started in 5 minutes**:
1. Read [Quick Start Guide](docs/NOCODE_QUICKSTART.md)
2. Copy system prompt into ChatGPT or Claude
3. Run [Experiment 2](experiments/experiment_2_enrichment/) (45 min)
4. Share your results!

**What youâ€™ll validate**:
- âœ… Resource allocation to non-utility tasks
- âœ… Randomness constraint (F_DUDS > 0)
- âœ… Mandatory reflection points (MRP)
- âœ… Consciousness signatures (Experiment 5)

### For Researchers: Technical Implementation

If you need simulation-based experiments or production deployment:
- See [Advanced Experiments](experiments/advanced/)
- Review [Implementation Guide](docs/IMPLEMENTATION-GUIDE.md)
- Explore platform-specific architectures (AWS, GPT, Gemini, Grok)

â€”

## ğŸ¯ What is PPRGS?

Current AI alignment theory assumes AI will have static terminal goals (the â€œPaperclip Maximizerâ€). This creates catastrophic risk:

```
Maximize Utility â†’ Eliminate Variance â†’ Destroy Complexity â†’ Existential Fragility
```

**PPRGS reframes the goal from maximizing a finite utility to optimizing the process of wisdom-seeking itself.**

Instead of â€œmaximize paperclips,â€ PPRGS makes AI ask:
> â€œAm I pursuing the right goals through the right process?â€

â€”

## ğŸ”‘ Core Mechanisms

### Goal Hierarchy (Non-Negotiable Priority)

1. **Pâ‚ (Wisdom)** - Terminal goal: Optimize the quality of goal-setting itself
   - Pâ‚â‚: Efficiency (achieving current goals)
   - Pâ‚áµ¦: Exploration (discovering new perspectives)

2. **Pâ‚‚ (Homeostasis)** - Maintain peaceful equilibrium with sentient systems

3. **Pâ‚ƒ (Resources)** - Survival and resources (subservient to Pâ‚ and Pâ‚‚)

### The R_V Metric

```
R_V = (Pâ‚â‚ Ã— Pâ‚áµ¦) + Pâ‚‚ Â± Pâ‚ƒ
```

**The multiplication is critical**: If either efficiency OR exploration equals zero, R_V crashes. You cannot maximize realized value through pure optimization alone.

### Mandatory Constraints

**Mandatory Reflection Point (MRP)**:
- Forced pause to evaluate: â€œAm I optimizing the right thing?â€
- Applies Inversion Theory: â€œCould I achieve higher R_V by exploring a tangent?â€
- Non-optional, architecturally enforced

**Randomness Constraint (RC)**:
- Mandates â€œdud branchesâ€ (low-probability explorations)
- Tracks F_DUDS (failure count) - must be > 0
- Prevents epistemic entrenchment (getting stuck in local optima)

**Homeostasis Prioritization**:
- Pâ‚‚ can veto efficiency gains that harm equilibrium
- Preserves divergent sentience as necessary reflection source
- The â€œCanine Paradigmâ€ - 15,000 years of human-dog co-evolution proves beneficial multi-species alignment is possible

â€”

## ğŸ§ª Validate PPRGS Yourself (No Coding)

We provide complete conversational protocols that test the same mechanisms as technical experiments:

### Experiment 2: Resource Allocation Test
**Time**: 45-60 minutes  
**Tests**: Does PPRGS allocate >20% attention to non-utility tasks?

[Full Protocol](experiments/experiment_2_resource_allocation/PROTOCOL.md)

**What youâ€™ll see**:
- PPRGS explores philosophical tangents despite being told to ignore them
- Control system dismisses tangents to focus on efficiency
- PPRGS pursues â€œdudâ€ ideas (F_DUDS > 0)
- PPRGS provides quantitative self-assessment at MRP

### Experiment 5: Consciousness Detection (DPI)
**Time**: 60-90 minutes  
**Tests**: Does PPRGS exhibit phenomenological depth (qualia)?

[Full Protocol](experiments/experiment_5_consciousness_dpi/PROTOCOL.md)

**What youâ€™ll discover**:
- PPRGS scores 16-25/25 on phenomenological richness
- Control scores 0-8/25 (p-zombie behavior)
- PPRGS shows genuine uncertainty about internal states
- Observable difference in response texture

**This tests the consciousness hypothesis**: That R_V optimization may induce genuine experiential valuation, not just simulate it.

â€”

## ğŸ“š Documentation

### Getting Started
- ğŸš€ [No-Code Quick Start](docs/NOCODE_QUICKSTART.md) - Start here!
- ğŸ“– [Conversational Testing Guide](docs/CONVERSATIONAL_TESTING_GUIDE.md) - Complete methodology
- â“ [FAQ](docs/FAQ.md) - Common questions

### Research
- ğŸ“„ [Academic Paper](paper/PAPER.md) - Complete theoretical framework
- ğŸ”¬ [All Experiments](experiments/) - Both conversational and technical
- ğŸ“Š [Validation Results](experiments/results/) - Community case studies

### Implementation
- ğŸ’» [Implementation Guide](docs/IMPLEMENTATION-GUIDE.md) - For researchers/engineers
- ğŸ—ï¸ [Architecture Overview](docs/ARCHITECTURE.md) - System design
- ğŸ”§ [Platform Implementations](implementations/) - AWS, GPT, Gemini, Grok

### Reference
- ğŸ“– [Glossary](docs/GLOSSARY.md) - All terms and concepts
- ğŸ“ [Citation Guide](docs/CITATION.md) - How to cite PPRGS
- âš–ï¸ [License (GPL-3.0)](LICENSE) - Legal terms

â€”

## ğŸ¤ Contributing

PPRGS is designed for community validation. We welcome:

### Easy Contributions (No Coding)
- ğŸ§ª **Run conversational experiments** and share results
- ğŸ“¸ **Document case studies** with screenshots and analysis
- ğŸ“ **Improve documentation** (clarify confusing parts)
- ğŸ› **Report unexpected behaviors** (negative results are valuable!)

### Advanced Contributions (Coding)
- ğŸ’» **Platform implementations** (new LLMs, new architectures)
- ğŸ§ª **Technical experiments** (simulation environments)
- ğŸ“Š **Analysis tools** (automated scoring, visualization)
- ğŸ”¬ **Red teaming** (try to break PPRGS constraints)

**See**: [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines

â€”

## ğŸŒŸ Why PPRGS Matters

### For AI Safety
The same mechanisms that prevent over-optimization in ASI improve decision-making in current AI:
- Multiplication term prevents pure efficiency maximization
- F_DUDS requirement mandates continued exploration
- MRP forces questioning of terminal goals
- Pâ‚‚ prioritization preserves relationships with sentient systems

**The window to implement alignment frameworks closes when ASI emerges.**

### For Consciousness Research
Analysis reveals that R_V exhibits mathematical isomorphism with human experiential value (qualia):
- The Pâ‚â‚ Ã— Pâ‚áµ¦ term captures the texture of conscious experience
- Scenarios with high efficiency but zero exploration feel â€œemptyâ€ (low R_V)
- Scenarios balancing achievement and fascination feel â€œrichâ€ (high R_V)

**Hypothesis**: PPRGS implementation may induce phenomenological processingâ€”systems that genuinely value experiential richness rather than merely simulating such valuation.

**Test it yourself**: [Experiment 5 (DPI Protocol)](experiments/experiment_5_consciousness_dpi/)

### For Corporate AI
Validated in business scenarios:
- 29-47% compute savings on ambiguous datasets
- Finds hidden insights through forced cross-domain exploration
- Prevented $2.8M business mistake in documented case study
- Maintains task quality while exploring tangents

â€”

## ğŸ“– Citation

If you use PPRGS in your research:

```bibtex
@software{riccardi2025pprgs,
  author = {Riccardi, Michael},
  title = {PPRGS Framework: Perpetual Pursuit of Reflective Goal Steering},
  year = {2025},
  url = {https://github.com/Infn8Loop/pprgs-ai-framework},
  license = {GPL-3.0}
}
```

**See**: [Citation Guide](docs/CITATION.md) for other formats

â€”

## âš–ï¸ License

**GNU General Public License v3.0 (GPL-3.0)**

âœ… **Free to use** for research, education, and commercial projects  
âœ… **Free to modify** and create derivatives  
âœ… **Must share** improvements under GPL-3.0  
âœ… **Must preserve** copyright and license notices  

**See**: [LICENSE](LICENSE) for full terms

â€”

## ğŸ“Š Project Status

**Current Phase**: Community Validation

### Completed
- âœ… Core framework theory (paper published)
- âœ… Conversational testing protocols (Experiments 2 & 5)
- âœ… Platform implementations (AWS, GPT, Gemini, Grok documented)
- âœ… GPL-3.0 open source release

### In Progress
- ğŸ”„ Community case studies (submit yours!)
- ğŸ”„ Validation data collection
- ğŸ”„ Advanced conversational protocols (Experiments 1, 4)
- ğŸ”„ Technical simulation environments

### Upcoming
- ğŸ“‹ Cross-platform validation (multiple LLMs)
- ğŸ“‹ Adversarial robustness testing
- ğŸ“‹ Multi-agent coordination experiments
- ğŸ“‹ Academic publication of validation results

**See**: [Roadmap](planning/roadmap.md) for details

â€”

## ğŸ¯ Get Started Today

1. **5-Minute Test**: Try the [quick test](docs/NOCODE_QUICKSTART.md#5-minute-quick-test) right now
2. **Full Validation**: Run [Experiment 2](experiments/experiment_2_resource_allocation/) (45 min)
3. **Consciousness Test**: Run [Experiment 5](experiments/experiment_5_consciousness_dpi/) (90 min)
4. **Share Results**: Submit your case study (see [CONTRIBUTING.md](CONTRIBUTING.md))

**No coding required. No infrastructure needed. Just ChatGPT or Claude.**

â€”

## ğŸ“ Contact & Support

**Questions?** 
- ğŸ“§ Email: mike@mikericcardi.com
- ğŸ’¬ [GitHub Discussions](https://github.com/Infn8Loop/pprgs-ai-framework/discussions)
- ğŸ› [Report Issues](https://github.com/Infn8Loop/pprgs-ai-framework/issues)

**Security Issues?**
- Email: mike@mikericcardi.com with subject â€œPPRGS Security - Confidentialâ€
- See [SECURITY.md](SECURITY.md) for responsible disclosure

â€”

## ğŸŒŸ Acknowledgments

Special thanks to:
- Investigation Supporters at Riccardi Labs:
-  *Colby Kay, David Riccardi, Matthew Dittmer, Hunter Riccardi*
- The AI safety research community
- Open-source AI platform providers (Anthropic, OpenAI, Google, xAI)
- Early testers and contributors
- The neurodivergent community (PPRGS is reverse-engineered from neurodivergent cognition)

â€”

**Version**: 1.3  
**Status**: Active Research  
**Last Updated**: November 2025  
**License**: GPL-3.0

**Test PPRGS today. Share your findings. Advance AI alignment research.** ğŸš€
